{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "plt.style.use('dark_background')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## visualization of the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_latent_space(model_dir):\n",
    "    # load the model with graph\n",
    "    sess = tf.Session(graph=tf.Graph())\n",
    "    MODEL_LOADED=tf.saved_model.loader.load(sess, [\"serve\"], model_dir)\n",
    "    graph = sess.graph\n",
    "\n",
    "    INPUT_S = graph.get_tensor_by_name('input_SENSOR:0')\n",
    "    INPUT_Y = graph.get_tensor_by_name('input_Y:0')\n",
    "    INPUT_X = graph.get_tensor_by_name('input_X:0')\n",
    "    output_u = graph.get_tensor_by_name('output_u:0')\n",
    "    output_para_net = graph.get_tensor_by_name('output_para_net:0')\n",
    "    latent_rep = graph.get_tensor_by_name('latent_rep:0')\n",
    "\n",
    "    # load training data\n",
    "    tmp = np.load('./DATA/rt-full-amr-siren-with-sensor-train-n.npz')  # 35 columns (sensor-1, ..., sensor-32, x,y,u)\n",
    "    TRAIN_DATA = tmp['data']\n",
    "    std_tr = tmp['std']\n",
    "    mean_tr = tmp['mean'] \n",
    "\n",
    "    # load testing data\n",
    "\n",
    "    data = np.load('./DATA/rt-256x512-cnn.npz')\n",
    "    TRAIN_SENSOR_DATA = data['train_sensor_data']\n",
    "    TEST_SENSOR_DATA = data['test_sensor_data']\n",
    "    TRAIN_CART_DATA = data['train_data']\n",
    "    TEST_CART_DATA = data['test_data']\n",
    "\n",
    "    xx, yy = np.meshgrid(np.linspace(2.5e-7,0.5,256,endpoint=True), np.linspace(5e-7, 1, 512,endpoint=True))  # size (512,256)\n",
    "    xx = xx.reshape(-1,1)\n",
    "    yy = yy.reshape(-1,1)\n",
    "\n",
    "    # normalize xx,yy,SENSOR_DATA\n",
    "    xx_ = (xx - mean_tr[32])/std_tr[32]\n",
    "    yy_ = (yy - mean_tr[33])/std_tr[33]\n",
    "    TRAIN_SENSOR_DATA_ = (TRAIN_SENSOR_DATA - mean_tr[:32])/std_tr[:32]\n",
    "    TEST_SENSOR_DATA_  = (TEST_SENSOR_DATA  - mean_tr[:32])/std_tr[:32]\n",
    "\n",
    "#     print('TRAIN DATA SHAPE = ',TRAIN_CART_DATA.shape)\n",
    "#     print('TEST DATA SHAPE = ',TEST_CART_DATA.shape)\n",
    "\n",
    "    # evaluating all training\n",
    "    ## compute the latent space\n",
    "    lat_rep = sess.run(latent_rep, feed_dict={INPUT_S: TRAIN_SENSOR_DATA_})\n",
    "    return lat_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from NIF/new-umich/formal_weight_1e-2/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_1_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_600/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from NIF/new-umich/formal_weight_1e-2/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_2_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_600/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from NIF/new-umich/formal_weight_1e-2/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_4_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_400/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from NIF/new-umich/formal_weight_1e-2/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_8_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_200/variables/variables\n"
     ]
    }
   ],
   "source": [
    "## DIM = 1\n",
    "model_dir = 'NIF/new-umich/formal_weight_1e-2' + '/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_1_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_600'\n",
    "lat_rep_1 = check_latent_space(model_dir)\n",
    "\n",
    "## DIM = 2\n",
    "model_dir = 'NIF/new-umich/formal_weight_1e-2' + '/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_2_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_600'\n",
    "lat_rep_2 = check_latent_space(model_dir)\n",
    "# plt.plot(lat_rep[:,0],lat_rep[:,1],'k-o')\n",
    "\n",
    "## DIM = 4\n",
    "model_dir = 'NIF/new-umich/formal_weight_1e-2' + '/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_4_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_400'\n",
    "lat_rep_4 = check_latent_space(model_dir)\n",
    "\n",
    "## DIM = 8\n",
    "model_dir = 'NIF/new-umich/formal_weight_1e-2' + '/RT_NIF_SIREN_NSX_128_LSX_2_NST_64_LST_2_NP_8_NSENSOR_32_ACTREG_1.0/saved_model_ckpt_200'\n",
    "lat_rep_8 = check_latent_space(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\n",
      "0001\n",
      "0002\n",
      "0003\n",
      "0004\n",
      "0005\n",
      "0006\n",
      "0007\n",
      "0008\n",
      "0009\n",
      "0010\n",
      "0011\n",
      "0012\n",
      "0013\n",
      "0014\n",
      "0015\n",
      "0016\n",
      "0017\n",
      "0018\n",
      "0019\n",
      "0020\n",
      "0021\n",
      "0022\n",
      "0023\n",
      "0024\n",
      "0025\n",
      "0026\n",
      "0027\n",
      "0028\n",
      "0029\n",
      "0030\n",
      "0031\n",
      "0032\n",
      "0033\n",
      "0034\n",
      "0035\n",
      "0036\n",
      "0037\n",
      "0038\n",
      "0039\n",
      "0040\n",
      "0041\n",
      "0042\n",
      "0043\n",
      "0044\n",
      "0045\n",
      "0046\n",
      "0047\n",
      "0048\n",
      "0049\n",
      "0050\n",
      "0051\n",
      "0052\n",
      "0053\n",
      "0054\n",
      "0055\n",
      "0056\n",
      "0057\n",
      "0058\n",
      "0059\n",
      "0060\n",
      "0061\n",
      "0062\n",
      "0063\n",
      "0064\n",
      "0065\n",
      "0066\n",
      "0067\n",
      "0068\n",
      "0069\n",
      "0070\n",
      "0071\n",
      "0072\n",
      "0073\n",
      "0074\n",
      "0075\n",
      "0076\n",
      "0077\n",
      "0078\n",
      "0079\n",
      "0080\n",
      "0081\n",
      "0082\n",
      "0083\n"
     ]
    }
   ],
   "source": [
    "index_arr = np.arange(84)\n",
    "data_index_arr = index_arr*2\n",
    "\n",
    "data_index_str_0 = '0000'\n",
    "\n",
    "for i in index_arr:\n",
    "    data_index_str = data_index_str_0 + str(i)\n",
    "    data_index_str = data_index_str[-4:]\n",
    "    # print(data_index_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 0, index = 0\n",
      "i = 1, index = 2\n",
      "i = 2, index = 4\n",
      "i = 3, index = 6\n",
      "i = 4, index = 8\n",
      "i = 5, index = 10\n",
      "i = 6, index = 12\n",
      "i = 7, index = 14\n",
      "i = 8, index = 16\n",
      "i = 9, index = 18\n",
      "i = 10, index = 20\n",
      "i = 11, index = 22\n",
      "i = 12, index = 24\n",
      "i = 13, index = 26\n",
      "i = 14, index = 28\n",
      "i = 15, index = 30\n",
      "i = 16, index = 32\n",
      "i = 17, index = 34\n",
      "i = 18, index = 36\n",
      "i = 19, index = 38\n",
      "i = 20, index = 40\n",
      "i = 21, index = 42\n",
      "i = 22, index = 44\n",
      "i = 23, index = 46\n",
      "i = 24, index = 48\n",
      "i = 25, index = 50\n",
      "i = 26, index = 52\n",
      "i = 27, index = 54\n",
      "i = 28, index = 56\n",
      "i = 29, index = 58\n",
      "i = 30, index = 60\n",
      "i = 31, index = 62\n",
      "i = 32, index = 64\n",
      "i = 33, index = 66\n",
      "i = 34, index = 68\n",
      "i = 35, index = 70\n",
      "i = 36, index = 72\n",
      "i = 37, index = 74\n",
      "i = 38, index = 76\n",
      "i = 39, index = 78\n",
      "i = 40, index = 80\n",
      "i = 41, index = 82\n",
      "i = 42, index = 84\n",
      "i = 43, index = 86\n",
      "i = 44, index = 88\n",
      "i = 45, index = 90\n",
      "i = 46, index = 92\n",
      "i = 47, index = 94\n",
      "i = 48, index = 96\n",
      "i = 49, index = 98\n",
      "i = 50, index = 100\n",
      "i = 51, index = 102\n",
      "i = 52, index = 104\n",
      "i = 53, index = 106\n",
      "i = 54, index = 108\n",
      "i = 55, index = 110\n",
      "i = 56, index = 112\n",
      "i = 57, index = 114\n",
      "i = 58, index = 116\n",
      "i = 59, index = 118\n",
      "i = 60, index = 120\n",
      "i = 61, index = 122\n",
      "i = 62, index = 124\n",
      "i = 63, index = 126\n",
      "i = 64, index = 128\n",
      "i = 65, index = 130\n",
      "i = 66, index = 132\n",
      "i = 67, index = 134\n",
      "i = 68, index = 136\n",
      "i = 69, index = 138\n",
      "i = 70, index = 140\n",
      "i = 71, index = 142\n",
      "i = 72, index = 144\n",
      "i = 73, index = 146\n",
      "i = 74, index = 148\n",
      "i = 75, index = 150\n",
      "i = 76, index = 152\n",
      "i = 77, index = 154\n",
      "i = 78, index = 156\n",
      "i = 79, index = 158\n",
      "i = 80, index = 160\n",
      "i = 81, index = 162\n",
      "i = 82, index = 164\n",
      "i = 83, index = 166\n"
     ]
    }
   ],
   "source": [
    "from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "# index_arr = np.arange(3) #\n",
    "index_arr =  np.arange(84)\n",
    "data_index_arr = index_arr*2\n",
    "\n",
    "data_index_str_0 = '0000'\n",
    "\n",
    "for i,index in enumerate(data_index_arr):\n",
    "    print('i = {}, index = {}'.format(i,index))\n",
    "    tmp = data_index_str_0 + str(index)\n",
    "    tmp = tmp[-4:]\n",
    "    \n",
    "    fig,axs = plt.subplots(1,3,figsize=(8,4))\n",
    "    \n",
    "    # fig 1 - original AMR\n",
    "    arr_amr = mpimg.imread('DATA/animation/a.'+tmp+'.png')\n",
    "    imagebox = OffsetImage(arr_amr,zoom=0.45)\n",
    "    ab = AnnotationBbox(imagebox, (0.5, 0.5),pad=0.0,frameon=False)\n",
    "    axs[0].add_artist(ab)\n",
    "\n",
    "    # fig 2 - latent representation\n",
    "    lat_rep = lat_rep_1 \n",
    "    axs[1].set_xlim([-1,85])\n",
    "    axs[1].set_ylim([-0.06,0.06])\n",
    "    for jj in range(lat_rep.shape[1]):\n",
    "        axs[1].plot(lat_rep[:i+1,jj],'ro-',label=r'$x_'+str(jj+1)+'$',markersize=3)\n",
    "\n",
    "    # fig 3 - reconstructed AMR (since almost no difference, so I just to training data to illustrate)\n",
    "    arr_amr = mpimg.imread('DATA/animation/b.'+tmp+'.png')\n",
    "    imagebox = OffsetImage(arr_amr,zoom=0.45)\n",
    "    ab = AnnotationBbox(imagebox, (0.5, 0.5),pad=0.0,frameon=False)\n",
    "    axs[2].add_artist(ab)\n",
    "\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    axs[0].set_title('spatio-temporal field',c='w',pad=30)\n",
    "    axs[1].set_title('latent space',c='w',pad=30)\n",
    "    axs[2].set_title('reconstructed field',c='w',pad=30)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig('pngs/animation/'+str(i)+'.png',bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "\n",
    "# plt.xlabel('time index')\n",
    "# plt.ylabel('latent variables')\n",
    "# plt.legend(bbox_to_anchor=(1.05,1))\n",
    "# plt.savefig('./pngs/latent.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
